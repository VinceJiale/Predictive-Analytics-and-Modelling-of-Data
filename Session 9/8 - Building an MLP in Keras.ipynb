{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an MLP in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity we will build an MLP model for the churn dataset. \n",
    "Let's first import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 22 kB/s s eta 0:00:01                    | 15.7 MB 2.5 MB/s eta 0:02:03                      | 19.1 MB 2.5 MB/s eta 0:02:0222.7 MB 2.5 MB/s eta 0:02:0025.3 MB 2.5 MB/s eta 0:01:5928.7 MB 957 kB/s eta 0:05:05     |███▋                            | 35.8 MB 957 kB/s eta 0:04:58                    | 42.8 MB 957 kB/s eta 0:04:507 kB/s eta 0:04:46| 53.3 MB 957 kB/s eta 0:04:39kB/s eta 0:04:36kB/s eta 0:04:32957 kB/s eta 0:04:30��▋                         | 66.0 MB 957 kB/s eta 0:04:26��█                         | 69.3 MB 957 kB/s eta 0:04:23█████▎                        | 72.6 MB 957 kB/s eta 0:04:19 MB 957 kB/s eta 0:04:16 MB 957 kB/s eta 0:04:12ta 0:00:040404               | 93.4 MB 66.2 MB/s eta 0:00:04               | 96.9 MB 66.2 MB/s eta 0:00:04                | 103.6 MB 66.2 MB/s eta 0:00:04MB/s eta 0:00:04MB/s eta 0:00:04█▍                    | 114.2 MB 66.2 MB/s eta 0:00:04█▊                    | 116.9 MB 66.2 MB/s eta 0:00:04██                    | 120.4 MB 66.2 MB/s eta 0:00:04 |█████████████▋                  | 136.5 MB 66.2 MB/s eta 0:00:03██████████                  | 139.8 MB 66.2 MB/s eta 0:00:03�█████████▎                 | 143.2 MB 56.5 MB/s eta 0:00:04| 146.7 MB 56.5 MB/s eta 0:00:04| 150.0 MB 56.5 MB/s eta 0:00:04/s eta 0:00:03/s eta 0:00:030.2 MB 56.5 MB/s eta 0:00:03     |████████████████▍               | 163.9 MB 56.5 MB/s eta 0:00:03��▊               | 167.9 MB 56.5 MB/s eta 0:00:03            | 170.8 MB 56.5 MB/s eta 0:00:03��█████████████▎              | 173.3 MB 56.5 MB/s eta 0:00:03�▋              | 176.9 MB 56.5 MB/s eta 0:00:03��██████████████              | 180.3 MB 56.5 MB/s eta 0:00:03| 183.8 MB 56.5 MB/s eta 0:00:03MB/s eta 0:00:03█             | 190.8 MB 56.5 MB/s eta 0:00:03��█▍            | 193.8 MB 56.5 MB/s eta 0:00:03��█▊            | 197.1 MB 56.5 MB/s eta 0:00:03████████████████████            | 199.8 MB 19.4 MB/s eta 0:00:07   |████████████████████▍           | 203.8 MB 19.4 MB/s eta 0:00:07��████████████████▊           | 207.1 MB 19.4 MB/s eta 0:00:06213.5 MB 19.4 MB/s eta 0:00:06:00:064 MB/s eta 0:00:06        | 223.7 MB 19.4 MB/s eta 0:00:05        | 227.3 MB 19.4 MB/s eta 0:00:05�██████████▎        | 233.4 MB 19.4 MB/s eta 0:00:05�██████████▋        | 236.9 MB 19.4 MB/s eta 0:00:050 MB 19.4 MB/s eta 0:00:05██████████████████████▎       | 243.4 MB 19.4 MB/s eta 0:00:04��████████████████▋       | 246.8 MB 19.4 MB/s eta 0:00:04███████████████████████       | 250.5 MB 19.4 MB/s eta 0:00:04�██▎      | 253.5 MB 19.4 MB/s eta 0:00:04MB/s eta 0:00:04| 259.2 MB 60.9 MB/s eta 0:00:02��██▎     | 262.8 MB 60.9 MB/s eta 0:00:01MB/s eta 0:00:01��██████████████████▉     | 269.2 MB 60.9 MB/s eta 0:00:01��█████████████▎    | 272.7 MB 60.9 MB/s eta 0:00:01��█████████████████████████▌    | 275.6 MB 60.9 MB/s eta 0:00:01��███████████████████████▉    | 279.1 MB 60.9 MB/s eta 0:00:01| 282.6 MB 60.9 MB/s eta 0:00:01��████▌   | 285.9 MB 60.9 MB/s eta 0:00:01██████████████████▉   | 289.0 MB 60.9 MB/s eta 0:00:01ta 0:00:01ta 0:00:010.9 MB/s eta 0:00:01�█▍ | 303.8 MB 60.9 MB/s eta 0:00:01�█▋ | 306.9 MB 60.9 MB/s eta 0:00:01�██ | 310.1 MB 60.9 MB/s eta 0:00:01:00:01██████████████| 320.0 MB 54.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 37.9 MB/s eta 0:00:01               | 3.2 MB 37.9 MB/s eta 0:00:01 |██████████▍                     | 6.5 MB 37.9 MB/s eta 0:00:01��██████████████                | 10.1 MB 37.9 MB/s eta 0:00:01       | 13.0 MB 37.9 MB/s eta 0:00:01�██████████████████▏      | 15.8 MB 37.9 MB/s eta 0:00:01 MB 37.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 1.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 56.3 MB/s eta 0:00:01/s eta 0:00:01��█▊| 6.7 MB 56.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 454 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 56.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.33.2-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 57.6 MB/s eta 0:00:01███████████▎                    | 1.3 MB 57.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 60.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 61.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 55.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.0.0.post20200311)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 65.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=7b3f89475c6202015a343f48162864d86045887b41b1e426815477687aa1bbbe\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70936 sha256=6a4abffc4260d623e393fb3ac0ee4257d73b94faf70940a7e0976eabc66e1acc\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: numpy, astunparse, opt-einsum, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, werkzeug, absl-py, grpcio, tensorboard-plugin-wit, markdown, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-estimator, termcolor, keras-preprocessing, gast, google-pasta, wrapt, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.18.5 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# need to install tensorflow and keras first, may take a few minutes\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the churn dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('churn_ibm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know the pre-processing steps from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = df.drop(['Churn','customerID'],axis=1)\n",
    "\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == np.object:\n",
    "        X = pd.concat([X,pd.get_dummies(X[column], prefix=column, drop_first=True)],axis=1).drop([column],axis=1)\n",
    "\n",
    "# Also for neural networks, it's best to scale the input variables        \n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = pd.get_dummies(y, prefix='churn', drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build an MLP, we are going to use the popular Keras library, which acts as a high-level shell around TensorFlow. First, we create our training and test sets again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import the Keras modules we need, and store the input dimension (number of features), and the output dimension (number of classes -1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension:  30\n",
      "Output dimension:  1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "print('Input dimension: ', input_dim)\n",
    "print('Output dimension: ', output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the model. We use a sequential model, meaning we can sequentially add layers to it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance (Sequential, as we add each layer in order of appearance)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and connect to 50 hidden neurons\n",
    "model.add(Dense(50,input_dim=input_dim))\n",
    "\n",
    "# Connect the neurons to the next 50 neurons\n",
    "model.add(Dense(50))\n",
    "\n",
    "# Connect the previous layer to the output layer\n",
    "model.add(Dense(output_dim))\n",
    "\n",
    "# Add a final layer for classification based on the sigmoid function (since this is binary)\n",
    "# We could add this after every layer (more on this later)\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Create the model with an optimizer, loss function, and evaluation metric. We will cover these in more detail later.\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ```Dense()``` layer, which connects all inputs to all outputs (a fully connected layer). Now, we can summarise the model and obtain predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,151\n",
      "Trainable params: 4,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7519\n",
      "WARNING:tensorflow:From <ipython-input-13-486e074c162d>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:From <ipython-input-13-486e074c162d>:7: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Obtains the results as a class (here 0/1)\n",
    "prediction_class = model.predict_classes(X_test)\n",
    "# Obtains the results as a probability\n",
    "prediction_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our outcomes to calculate the final evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7867298578199052\n",
      "AUC: 0.81831101067768\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test,prediction_class))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a bad result. We will learn how to improve it later on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
