{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a logistic regression #\n",
    "\n",
    "Let's look into how to build a logistic regression model using ```statsmodels``` and ```sklearn```. Again, the former is better suited to return a descriptive output, while the latter can be used with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   const  Unnamed: 0  Bad_2  ID  Duration  VAR5  VAR8  VAR11  VAR13  VAR16  \\\n",
      "0    1.0           0      0   1         6  1169     4      4     67      2   \n",
      "1    1.0           1      1   2        48  5951     2      2     22      1   \n",
      "2    1.0           2      0   3        12  2096     2      3     49      1   \n",
      "3    1.0           3      0   4        42  7882     2      4     45      1   \n",
      "4    1.0           4      1   5        24  4870     3      4     53      2   \n",
      "\n",
      "   ...  VAR12_A124  VAR14_A142  VAR14_A143  VAR15_A152  VAR15_A153  \\\n",
      "0  ...           0           0           1           1           0   \n",
      "1  ...           0           0           1           1           0   \n",
      "2  ...           0           0           1           1           0   \n",
      "3  ...           0           0           1           0           1   \n",
      "4  ...           1           0           1           0           1   \n",
      "\n",
      "   VAR17_A172  VAR17_A173  VAR17_A174  VAR19_A192  VAR20_A202  \n",
      "0           0           1           0           1           0  \n",
      "1           0           1           0           0           0  \n",
      "2           1           0           0           0           0  \n",
      "3           0           1           0           0           0  \n",
      "4           0           1           0           0           0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we can use the credit dataset\n",
    "credit = pd.read_csv(\"credit_regress.csv\")\n",
    "credit.rename (columns={'VAR1_A14' : 'No_account', 'VAR2' : 'Duration'}, inplace=True)\n",
    "\n",
    "# Again, we need to add a constant\n",
    "credit = sm.add_constant(credit)\n",
    "print(credit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535760\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Bad_2   No. Observations:                  700\n",
      "Model:                          Logit   Df Residuals:                      697\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 12 Nov 2019   Pseudo R-squ.:                  0.1064\n",
      "Time:                        16:29:04   Log-Likelihood:                -375.03\n",
      "converged:                       True   LL-Null:                       -419.70\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.983e-20\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.1121      0.185     -5.999      0.000      -1.476      -0.749\n",
      "No_account    -1.5785      0.208     -7.572      0.000      -1.987      -1.170\n",
      "Duration       0.0340      0.007      4.617      0.000       0.020       0.048\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# we will use two variables, and will split the data into training and testing\n",
    "X=credit[[\"const\",\"No_account\", \"Duration\"]]\n",
    "Y=credit[[\"Bad_2\"]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=2) \n",
    "\n",
    "# This time, we use the logit function\n",
    "logreg = sm.Logit(Y_train, X_train)\n",
    " \n",
    "result = logreg.fit()\n",
    "prob1 = result.predict(X_test)\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replicate this with ```sklearn``` to some extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept\n",
      "[-0.55222617]\n",
      "Coefficients\n",
      "[[-0.55222617 -1.51749913  0.03313594]]\n",
      "Odds Ratios\n",
      "[[0.57566685 0.21925954 1.03369104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train,Y_train.values.ravel())\n",
    "\n",
    "print('Intercept')\n",
    "print(logreg.intercept_)\n",
    "print (\"Coefficients\")\n",
    "print(logreg.coef_)\n",
    "print (\"Odds Ratios\")\n",
    "print (np.exp(logreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients vary slighly, possible due to the solver used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters give the effects on logit. Odds ratios give the effects on odds. Intercept is of little interest usually. \n",
    "\n",
    "Not having a checking account decreases logit by -1.52/-1.58 as compared to having it. It also means that Odds are reduced by a factor of 0.21. In other words, Odds of Default/Bad are almost 5 times lower for those without a checking account.\n",
    "\n",
    "For Duration an increase of one month (one unit) means an increase in logit of 0.03. Or an increase in odds by a factor of 1.03. A convenient way of interpreting the effect on odds for a numeric variable is to think of percentage deviation from 1, i.e. $(e^\\beta - 1) \\times 100$ indicates the percentage increase or decrease due to a one-unit change in the predictor.  So for Duration, a one month increase leads to a 3% increase in odds. Therefore, loans with longer duration are higher risks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time value: [0.00363302 0.00283551 0.00261807 0.00263596 0.02295828]\n",
      "score_time value: [0.00572824 0.00438762 0.00404811 0.00400805 0.00737143]\n",
      "test_roc_auc value: [0.64841463 0.730625   0.708375   0.729125   0.77790404]\n",
      "train_roc_auc value: [0.73562813 0.71790501 0.72047354 0.72009994 0.70346273]\n",
      "test_recall value: [0.17073171 0.225      0.175      0.2        0.2       ]\n",
      "train_recall value: [0.20625    0.1863354  0.20496894 0.19254658 0.19254658]\n",
      "test_precision value: [0.5        0.5625     0.58333333 0.8        0.57142857]\n",
      "train_precision value: [0.62264151 0.6        0.6        0.55357143 0.59615385]\n"
     ]
    }
   ],
   "source": [
    "# To check how predictive accuracy varies for different samples one can use cross_validate module \n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')\n",
    "# metrics you want to have computed\n",
    "metrics = ['roc_auc','recall','precision']\n",
    "\n",
    "# To show train metrics, we add the extra return_train_score parameter\n",
    "outcomes = cross_validate(classifier, X_train, Y_train.values.ravel(), scoring=metrics, cv=5, return_train_score=True)\n",
    "\n",
    "for metric in outcomes.keys():\n",
    "    print(metric+\" value: \"+str(outcomes[metric]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
